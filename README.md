# JaranReviewClassify
classify Japanese review from Jaran

本リポジトリには，Creative Commons BY-NC-SA 4.0 で公開されている
じゃらん口コミデータセットは含まれていない。


## 目的
じゃらんのレビューについて、SVMを用いた分類を行う。

## データセット
用いるデータセットはJapanese Realistic Textual Entailment Corpusのpn.tsvにある感情極性ラベルが付加されたレビューである。

data/pn.tsv

Data for sentiment analysis.

#	Explanation	Samples
0	ID of the example	pnXYZq00001
1	Label	1 (Positive), 0 (Neutral), -1 (Negative)
2	Text	駅まで近い。
3	Judges (JSON format)	{"0": 1, "1": 4}
4	Usage	train, dev, test

データの構造は上記の通り。

訓練データ
3888
開発用検証データ
1112
検証用データ
553

https://gotutiyan.hatenablog.com/entry/2020/09/10/181919#TfidfVectorizerの入出力



## 分類

1.TF-IDFに変換後、SVMで分類

ニュートラルを取り除いた２値での精度
(2959, 3906)
トレーニングデータに対する正解率： 1.00
dev: 0.8213866039952996
test: 0.821256038647343

ニュートラルを含む３値分類での精度
(3888, 5026)
トレーニングデータに対する正解率： 0.62
dev: 0.6267985611510791
test: 0.6112115732368897

→かなり精度に差が生じた。

誤分類結果を観察

| label | pred | text |
| 0 | 1 | 出張でお世話になりました。 |
| 0 | 1 | 朝食は普通でした。 |
| 0 | 1 | 新婚旅行で利用しました。 |
| 0 | 1 | お心遣いありがとうございました。 |
| 0 | 1 | 野球観戦で利用しました。 |
| 0 | 1 | 出張の前泊で利用しました。 |
| -1 | 1 | と感じてしまいました。 |
| 0 | 1 | )でした。 |
| 0 | 1 | 1泊お世話になりました。 |
| 0 | 1 | 普通のホテルです。 |
| 0 | 1 | 3回入りました。 |
| 0 | 1 | (̄▽ |
| 0 | 1 | お疲れ様です。 |
| 0 | 1 | 飲み会で利用しました。 |
| -1 | 1 | 期待していただけに残念でした。 |
| 0 | 1 | どうぞよろしくお願いします。 |
| 0 | 1 | 恋人旅行で利用しました。 |
| 0 | 1 | (^ω^ |
| 0 | 1 | 寝るだけなら充分です。 |
| -1 | 1 | 残念...。 |

- 欠損値を含むような中途半端な文
- 「利用しました」など事実のみ述べているようなもの
- 「残念」が含まれる文

欠損値→手作業で省く
「利用しました」などの肯定的でも否定的なレビューでも使われる表現
訓練データ上になかった単語であるために、

pn17q00821	-1	残念ですね。	{"-1": 3}	train
pn17q00946	-1	残念なのは朝食。	{"-1": 3}	train
pn17q00989	-1	と残念に思いました。	{"-1": 3}	train
pn17q01134	-1	全体的に残念でした。	{"-1": 3}	train
pn17q04999	-1	しいて言えば朝五時に入浴の際、洗面台横にかなりの量で前夜のゴミがそのまま残っておりそれがとても残念な気持ちになりました。	{"-1": 3}	train

pn17q02384	0	お風呂だけが残念でした。	{"-1": 1, "0": 2}	train
pn17q04644	0	オーナーさんは、感じがいい方で良かったんですが口コミが良かっただけに少し残念でした。	{"-1": 1, "0": 2}	train
pn17q05967	0	静かで居心地も良いしまた行きたい宿になりましたが、一点だけ残念だったのが夕食の海鮮舟盛りです。	{"-1": 1, "0": 2}	train

残念という単語が含まれるレビューは0,1のどちらか。
しかし、なぜか１に誤分類。

なぜか？

「残念」という単語は一見ネガティブよりだが、「〜〜だけが残念だった。」のように、中立的な表現にも用いられる。
また、TF-IDFが文そのものではなくあくまで単語の出現回数をもとにしている点も重要である。そのため、事実を述べただけの単語らでもポジ寄りの
文で用いられていればプラスの単語となってしまう。


TF-IDF は単語の意味ではなく出現分布に基づいて重み付けを行うため，
事実記述的な表現であっても，
ポジティブ文に多く出現すれば正例寄りの特徴として扱われてしまう。


訓練済みのword2vecを用いてレビューを埋め込みベクトルに変換して、その平均を入力として扱う

https://qiita.com/omuram/items/6570973c090c6f0cb060

学習済みモデルの語彙が物足りないため、対象の訓練用レビューで追加で再訓練する。
これでようやく残念にも対応！

[('良かっ', 0.859435498714447), ('。', 0.8512659072875977), ('感じ', 0.8384518623352051), ('、', 0.832740306854248), ('でし', 0.8315216302871704), ('!', 0.8249139785766602), ('良い', 0.8212375640869141), ('部屋', 0.8152942657470703), ('だっ', 0.7972613573074341), ('温泉', 0.7739769816398621)]

なんかあまりうまくいっていないような、、、
レビュー上では、褒めた上で残念ポイントを上げるため、ポジティブよりの語が類似に出ている気がする。

ともかく、再訓練したモデルで早速試す。
埋め込みベクトル化したため、訓練データのサイズは(3888, 300)となった。

--- tfidf ---
train： 0.62
dev: 0.6267985611510791
test: 0.6112115732368897

--- word2vec ---
train： 0.76
dev: 0.6924460431654677
test: 0.7160940325497287

検証用データで10%も向上している。

次に、実際にどのようなデータで改善が見られ、逆に悪化しているかを見てみる。
表示するのはdev用のデータである。
両方誤分類: 192
 514 | T: 0  TF: 1  W2V: 1  | 温泉は良かったのですが...
1035 | T:-1  TF: 1  W2V: 0  | 温泉は外ということもあり、利用しませんでした。
1037 | T:-1  TF: 1  W2V: 0  | 飲泉ができるということで少し飲んでみましたらしょっぱくてたくさんは飲めませんでした。
 528 | T:-1  TF: 1  W2V: 1  | 駐車場も狭いです。
  17 | T: 0  TF: 1  W2V: 1  | と思うほどでした。
1021 | T: 0  TF: 1  W2V:-1  | 部屋係りの人は明るく笑顔が素敵な人でしたが、料理を運ぶ時、ガチャガチャ音を立てて,,,。
  19 | T: 0  TF: 1  W2V:-1  | 今後に期待します。
 532 | T: 0  TF: 1  W2V:-1  | 目の前にはコンビニ。
  23 | T:-1  TF: 1  W2V: 1  | 本当に残念です。
 537 | T: 0  TF: 1  W2V: 1  | から始まりました。

TF-IDFのみ誤分類: 223
   0 | T: 0  P: 1  | 」と。
 513 | T: 0  P: 1  | 全体的には普通だと思います。
1024 | T:-1  P: 1  | 朝食のシステムをあまり確認しなかった私が悪かったのですが、毎日ほぼ同じ朝食のメニューでしたので飽きてしまいました。
   3 | T: 0  P: 1  | いつもお世話になります。
   4 | T: 0  P: 1  | バイクツーリングで利用しました。
1025 | T:-1  P: 1  | 全体的には好評価ですが、ただ残念なのが朝ごはん。
   7 | T: 0  P: 1  | 初めての宿泊です。
1032 | T: 0  P: 1  | 朝食が無料でしたので期待せずに利用。
1033 | T:-1  P: 1  | 少し言うのであればテレビがデカすぎて目が疲れました。
1036 | T:-1  P: 1  | ただシャワーカーテンに小さなシミが点在していたので、それが残念でした...

Word2Vecのみ誤分類: 150
1026 | T: 1  P: 0  | でもスタッフの方々の対応は少なからずそれをカバーしています。
 515 | T: 1  P: 0  | シルバーウィークで利用させていただきました。
1027 | T: 1  P: 0  | 滞在中と出張中も無料で車を預かっていただき、更にホテルから空港まで送ってくださり大変助かってます。
1029 | T: 1  P: 0  | 今回も温泉浴場でゆったりと心身共にリフレッシュしました。
1031 | T: 1  P: 0  | おすすめは濃いめの味噌汁です(笑)
 522 | T: 1  P: 0  | 我が家のお気に入りの宿です。
 523 | T: 1  P:-1  | 夕食は期待通り。
 524 | T: 1  P:-1  | 窓からの眺めは良かったです。
1034 | T: 1  P:-1  | おまけに部屋の正面が喫煙室&製氷機が置いてある場所でさらに良かったです。
1040 | T: 1  P:-1  | ・ホテルの全てのスタッフの挨拶が徹底されている。

意外と共通する語分類の文は少なかった。
しかし、興味深いのはTF-IDFがニュートラルな文の語分類が多いのに対して、word2vecのみのミスでは真ラベルのミスが多い。
狙い通り、文全体のニュアンスを踏まえたためにニュートラルに対応できるようになったということだと思う。

誤分類のラベルを確かめた。


both: ネガ:70, ニュートラル:122, ポジ:0
TF only: ネガ:84, ニュートラル:139, ポジ:0
w2v only: ネガ:2, ニュートラル:0, ポジ:148
dev_all: ネガ:160, ニュートラル:261, ポジ:691



